import os 
import numpy as np
import pandas as pd 
import tensorflow as tf 
from tensorflow.keras.layers  import (Layer, Dense, Embedding, Dropout, LayerNormalization,
                                    Conv1D, GlobalAveragePooling1D, Input, Add,
                                    Concatenate, BatchNormalization, Activation,
                                    Flatten, RepeatVector, Permute, Multiply, Lambda,
                                    SpatialDropout1D)
from tensorflow.keras.models  import Model, load_model 
from tensorflow.keras.regularizers  import l2 
from tensorflow.keras.optimizers  import Adam
from tensorflow.keras.callbacks  import (LearningRateScheduler, EarlyStopping,
                                       ModelCheckpoint, CSVLogger, TensorBoard)
from tensorflow.keras.utils  import to_categorical
from sklearn.model_selection  import train_test_split, StratifiedKFold 
from sklearn.metrics  import (confusion_matrix, accuracy_score, f1_score, matthews_corrcoef,
                            roc_auc_score, precision_score, recall_score,
                            precision_recall_curve, auc, average_precision_score,
                            classification_report)
from tensorflow.keras  import backend as K
from tensorflow_addons.losses  import SigmoidFocalCrossEntropy 
import matplotlib.pyplot  as plt 
import seaborn as sns
from imblearn.over_sampling  import SMOTE
from sklearn.preprocessing  import StandardScaler 
import json
import torch
import pyrosetta
from Bio.PDB import PDBParser
from Bio.SeqUtils import seq1
import re

def extract_protein_id_from_pdb_path(pdb_path):
    """
    ä» AlphaFold PDB æ–‡ä»¶è·¯å¾„ä¸­æå– UniProt ID
    æ”¯æŒæ ¼å¼ï¼šAF-P12345-F1-model_v4.pdb æˆ– AF_Q99999_F1_model_v3.pdb
    """
    filename = os.path.basename(pdb_path)
    
    # åŒ¹é…æ¨¡å¼1: AF-{id}-F1-model_vX.pdb
    match = re.search(r'AF-([A-Za-z0-9]+)-F\d+-model_v\d+', filename)
    if match:
        return match.group(1)
    
    # åŒ¹é…æ¨¡å¼2: AF_{id}_F1_model_vX.pdb
    match = re.search(r'AF_([A-Za-z0-9]+)_F\d+_model_v\d+', filename)
    if match:
        return match.group(1)
    
    # å…¶ä»–å¸¸è§æ ¼å¼ï¼ˆå¦‚ç›´æ¥æ˜¯ P12345.pdbï¼‰
    match = re.search(r'^([A-Za-z0-9]{5,6})\.pdb$', filename)
    if match:
        return match.group(1)
    
    raise ValueError(f"æ— æ³•ä»æ–‡ä»¶å '{filename}' ä¸­æå– protein_id")
# æ ‡å‡†æ°¨åŸºé…¸ä¸‰å­—æ¯åˆ°å•å­—æ¯çš„æ˜ å°„
one_letter = {
    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',
    'GLN': 'Q', 'GLU': 'E', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',
    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',
    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',
    'SEC': 'U', 'PYL': 'O', 'ASX': 'B', 'GLX': 'Z', 'XAA': 'X', 'XLE': 'J'
}
def extract_sequence_from_pdb(pdb_path, chain_id=None):
    """
    ä» PDB æ–‡ä»¶ä¸­æå–æ°¨åŸºé…¸åºåˆ—
    :param pdb_path: PDB æ–‡ä»¶è·¯å¾„
    :param chain_id: æŒ‡å®šé“¾ IDï¼ˆå¦‚ 'A'ï¼‰ï¼Œè‹¥ä¸º None åˆ™åˆå¹¶æ‰€æœ‰é“¾
    :return: æ°¨åŸºé…¸åºåˆ—ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("protein", pdb_path)
    
    sequences = {}
    
    for model in structure:
        for chain in model:
            chain_id = chain.id
            seq = []
            for residue in chain:
                if residue.get_id()[0] != " ":
                    continue
                resname = residue.get_resname()
                try:
                    seq.append(one_letter[resname])
                except KeyError:
                    # å¯¹äºæœªçŸ¥æ®‹åŸºï¼Œç”¨ 'X' è¡¨ç¤º
                    seq.append('X')
            sequences[chain_id] = ''.join(seq)
    
    # å¦‚æœåªæƒ³è¦ä¸€æ¡é“¾
    if chain_id is not None:
        return sequences.get(chain_id, "")
    
    # å¦åˆ™è¿”å›æ‰€æœ‰é“¾çš„åºåˆ—ï¼ˆç”¨ '/' åˆ†éš”ï¼‰
    return '/'.join([f"{k}:{v}" for k, v in sequences.items()])
# ==================== é…ç½®ç±» (ä¼˜åŒ–ç‰ˆ) ====================
class PredictConfig:
    def __init__(self):
        self.ptm_type  = 'phosphorylation'
        self.target_aa  = ['S', 'T']
        
        # è·¯å¾„é…ç½® 
        self.root_dir  = "/root/autodl-tmp/DeepPTMPred"
        self.esm_dir  = os.path.join(self.root_dir,  "pred/train_PTM")
        self.custom_esm_dir  = os.path.join(self.root_dir,  "pred/custom_esm")
        
        # æ¨¡å‹è·¯å¾„ 
        self.model_path  = os.path.join(self.esm_dir,  "model/models_phosphorylation_esm2/ptm_data_210_39_64_best_model.h5")

        self.esm_dim  = 1280
        self.struct_features  = ['sasa', 'phi', 'psi', 'secstruct','local_plDDT', 'avg_plDDT']
        self.struct_feature_dim  = 8
        self.embed_dim  = 64 
        self.num_heads  = 4
        self.ff_dim  = 256
        self.window_sizes  = [21, 33, 51]


class PyRosettaCalculator:
    def __init__(self, pdb_path=None):
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°PyRosettaåˆå§‹åŒ–çŠ¶æ€
        print("\n=== PyRosettaåˆå§‹åŒ–è°ƒè¯• ===")
        try:
            # åˆå§‹åŒ– PyRosettaï¼ˆå¿½ç•¥æœªçŸ¥æ®‹åŸºã€é™é»˜æ¨¡å¼ï¼‰
            pyrosetta.init("-ignore_unrecognized_res -mute all -ignore_zero_occupancy false")
            print("PyRosettaåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ PyRosettaåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

        self.pose = None
        self.plDDT_values = []
        self.res_sasa = {}

        if pdb_path:
            # è°ƒè¯•ä¿¡æ¯ï¼šéªŒè¯æ–‡ä»¶å¯è¯»æ€§
            abs_path = os.path.abspath(pdb_path)
            print(f"\n=== PDBæ–‡ä»¶éªŒè¯ ===")
            print(f"æ–‡ä»¶è·¯å¾„: {abs_path}")
            print(f"æ–‡ä»¶å­˜åœ¨: {os.path.exists(pdb_path)}")
            if not os.path.exists(pdb_path):
                raise FileNotFoundError(f"PDBæ–‡ä»¶ä¸å­˜åœ¨: {pdb_path}")

            print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(pdb_path)} å­—èŠ‚")

            # è°ƒè¯•ä¿¡æ¯ï¼šè¯»å–æ–‡ä»¶å¤´
            with open(pdb_path, 'r') as f:
                print("æ–‡ä»¶å‰5è¡Œå†…å®¹:")
                for i in range(5):
                    line = f.readline().strip()
                    print(f"  {line}")

            try:
                # åŠ è½½PDB
                print("\n=== PyRosettaåŠ è½½PDB ===")
                self.pose = pyrosetta.pose_from_pdb(pdb_path)
                print(f"åŠ è½½æˆåŠŸï¼æ€»æ®‹åŸºæ•°: {self.pose.total_residue()}")
                residue_1 = self.pose.residue(1)
                pdb_id = self.pose.pdb_info().pose2pdb(1)
                print(f"ç¬¬ä¸€ä¸ªæ®‹åŸº: {residue_1.name()} (ç¼–å· {pdb_id})")


                #=== è®¡ç®—SASAï¼šå¼ºåˆ¶åˆå§‹åŒ– + æ˜¾å¼è®¾ç½®å‚æ•° ===
                # === è®¡ç®—SASA ===
                print("\n=== è®¡ç®—SASA ===")
                try:
                    from pyrosetta.rosetta.core.scoring import calc_per_atom_sasa
                    from pyrosetta.rosetta.core.id import AtomID_Map_double_t
                    from pyrosetta.rosetta.utility import vector1_double
                
                    # åˆ›å»ºæ­£ç¡®çš„å‚æ•°ç±»å‹
                    atom_sasa = AtomID_Map_double_t()
                    residue_sasa = vector1_double()
                    
                    # åˆå§‹åŒ– atom_sasaï¼ˆå¿…é¡»ä¸ pose çš„åŸå­ç»“æ„åŒ¹é…ï¼‰
                    atom_sasa.resize(self.pose.size())
                    for i in range(1, self.pose.total_residue() + 1):
                        atom_sasa[i].resize(self.pose.residue(i).natoms())
                    
                    # è®¡ç®— SASA
                    calc_per_atom_sasa(
                        self.pose, 
                        atom_sasa, 
                        residue_sasa, 
                        1.4  # æ¢é’ˆåŠå¾„
                    )
                    
                    # æå–æ®‹åŸºçº§ SASA
                    for i in range(1, self.pose.total_residue() + 1):
                        total_sasa = residue_sasa[i]
                        # ç®€å•åˆ†é…ï¼šä¸»é“¾ SASA çº¦ä¸ºæ€» SASA çš„ 30%ï¼Œä¾§é“¾ 70%
                        bb_sasa = total_sasa * 0.3
                        sc_sasa = total_sasa * 0.7
                        self.res_sasa[i] = (total_sasa, bb_sasa, sc_sasa)
                    
                    # æ‰“å°å‰5ä¸ªæ®‹åŸºçš„ SASA å€¼
                    sample_res = min(5, self.pose.total_residue())
                    print(f"SASAè®¡ç®—æˆåŠŸï¼")
                    for i in range(1, sample_res + 1):
                        t, p, n = self.res_sasa[i]
                        print(f"  Res {i}: Total={t:.1f}Ã…Â² | Polar(BB)={p:.1f}Ã…Â² | Nonpolar(SC)={n:.1f}Ã…Â²")
                
                except Exception as e:
                    print(f"SASAè®¡ç®—å¤±è´¥: {str(e)}")
                    self.res_sasa = {i: (0.0, 0.0, 0.0) for i in range(1, self.pose.total_residue() + 1)}



                # === æå–plDDTï¼ˆä»B-factorï¼‰===
                print("\n=== æå–plDDT (B-factor) ===")
                parser = PDBParser()
                structure = parser.get_structure("protein", pdb_path)
                b_factors = [atom.get_bfactor() for atom in structure.get_atoms()]
                self.plDDT_values = b_factors
                avg_plddt = np.mean(b_factors)
                print(f"æå–åˆ° {len(b_factors)} ä¸ªBå› å­ï¼ˆplDDTï¼‰")
                print(f"   å¹³å‡plDDT: {avg_plddt:.2f}")

            except Exception as e:
                print(f"\nPyRosettaåŠ è½½PDBå¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                raise
        else:
            print("æœªæä¾›PDBè·¯å¾„")
    def calculate_features(self, residue_number):
        """å¸¦å®Œæ•´é”™è¯¯å¤„ç†çš„ç‰¹å¾è®¡ç®—ï¼ˆ8ç»´è¾“å‡ºï¼‰"""
        try:
            if not self.pose:
                raise ValueError("PyRosettaæœªåŠ è½½PDBç»“æ„")
            if residue_number < 1 or residue_number > self.pose.total_residue():
                raise ValueError(f"æ®‹åŸºç¼–å· {residue_number} è¶…å‡ºèŒƒå›´ [1, {self.pose.total_residue()}]")

            print(f"\nğŸ” è®¡ç®—æ®‹åŸº {residue_number} ç‰¹å¾...")

            # 1. SASAï¼šåªä¿ç•™ total_sasa
            total_sasa, _, _ = self.res_sasa.get(residue_number, (0.0, 0.0, 0.0))
            print(f"   SASA (total): {total_sasa:.2f} Ã…Â²")

            # 2. äºŒé¢è§’
            phi = self.pose.phi(residue_number)
            psi = self.pose.psi(residue_number)
            print(f"   phi={phi:.1f}, psi={psi:.1f}")

            # 3. äºŒçº§ç»“æ„ï¼ˆone-hot ç¼–ç ï¼šH=helix, E=sheet, L=loopï¼‰
            ss = self.pose.secstruct(residue_number)
            # é¡ºåºï¼šH, E, Lï¼ˆå¯¹åº” one-hotï¼‰
            ss_onehot = [1, 0, 0] if ss == 'H' else ([0, 1, 0] if ss == 'E' else [0, 0, 1])
            print(f"   äºŒçº§ç»“æ„: {ss} -> one-hot: {ss_onehot}")

            # 4. plDDT
            local_plddt = (
                self.plDDT_values[residue_number - 1]
                if self.plDDT_values and residue_number <= len(self.plDDT_values)
                else 85.0
            )
            avg_plddt = np.mean(self.plDDT_values) if self.plDDT_values else 85.0
            print(f"   local_plDDT={local_plddt:.1f}, avg_plDDT={avg_plddt:.1f}")


            # ç‰¹å¾é¡ºåºï¼šsasa, phi, psi, H, E, L, local_plDDT, avg_plDDT
            features = [
                total_sasa,           # sasa (1)
                phi, psi,             # phi, psi (2)
                ss_onehot[0],         # secstruct: H (1)
                ss_onehot[1],         # secstruct: E (1)
                ss_onehot[2],         # secstruct: L (1)
                local_plddt,          # local_plDDT (1)
                avg_plddt             # avg_plDDT (1)
            ]

            return np.array(features)

        except Exception as e:
            print(f" æ®‹åŸº {residue_number} ç‰¹å¾è®¡ç®—å¤±è´¥: {str(e)}")
            return np.array([0.0, 0.0, 0.0, 0, 0, 1, 85.0, 85.0])  # é»˜è®¤ sasa=0, phi=0, psi=0, ç»“æ„=L, plDDT=85
# ==================== è‡ªå®šä¹‰å±‚å®šä¹‰ (éœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´) ====================
class PositionEmbedding(Layer):
    def __init__(self, max_len=100, embed_dim=64, **kwargs):
        super().__init__(**kwargs)
        self.max_len = max_len
        self.embed_dim = embed_dim
        
    def build(self, input_shape):
        self.pos_emb = self.add_weight(
            name='position_embedding',
            shape=(self.max_len, self.embed_dim),
            initializer='glorot_uniform',
            trainable=True)
        super().build(input_shape)
    
    def call(self, x):
        seq_len = tf.shape(x)[1]
        positions = tf.range(start=0, limit=seq_len, delta=1)
        positions = tf.cast(positions, tf.int32)
        return x + tf.nn.embedding_lookup(self.pos_emb, positions)
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'max_len': self.max_len,
            'embed_dim': self.embed_dim
        })
        return config

class MultiHeadSelfAttention(Layer):
    def __init__(self, embed_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads
        
        assert self.head_dim * num_heads == embed_dim
        
    def build(self, input_shape):
        self.query = Dense(self.embed_dim)
        self.key = Dense(self.embed_dim)
        self.value = Dense(self.embed_dim)
        self.combine = Dense(self.embed_dim)
        super().build(input_shape)
    
    def call(self, x):
        batch_size = tf.shape(x)[0]
        
        q = self.query(x)
        k = self.key(x)
        v = self.value(x)
        
        q = tf.reshape(q, (batch_size, -1, self.num_heads, self.head_dim))
        q = tf.transpose(q, [0, 2, 1, 3])
        
        k = tf.reshape(k, (batch_size, -1, self.num_heads, self.head_dim))
        k = tf.transpose(k, [0, 2, 1, 3])
        
        v = tf.reshape(v, (batch_size, -1, self.num_heads, self.head_dim))
        v = tf.transpose(v, [0, 2, 1, 3])
        
        matmul_qk = tf.matmul(q, k, transpose_b=True)
        dk = tf.cast(tf.shape(k)[-1], tf.float32)
        scaled_attention = tf.nn.softmax(matmul_qk / tf.math.sqrt(dk), axis=-1)
        output = tf.matmul(scaled_attention, v)
        
        output = tf.transpose(output, [0, 2, 1, 3])
        output = tf.reshape(output, (batch_size, -1, self.embed_dim))
        return self.combine(output)
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'embed_dim': self.embed_dim,
            'num_heads': self.num_heads
        })
        return config

class TransformerBlock(Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.rate = rate
        
        self.att = MultiHeadSelfAttention(embed_dim, num_heads)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation='swish'),
            Dense(embed_dim)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)
    
    def call(self, inputs, training=True):
        attn_output = self.att(inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'embed_dim': self.embed_dim,
            'num_heads': self.num_heads,
            'ff_dim': self.ff_dim,
            'rate': self.rate
        })
        return config
# ==================== æ•°æ®åŠ è½½ä¸å¤„ç† (ä¼˜åŒ–ç‰ˆ) ====================
class PTMPredictDataLoader:
    def __init__(self, config):
        self.config = config
        self.rosetta_calc = None
        
    def init_pyrosetta(self, pdb_path):
        """å»¶è¿Ÿåˆå§‹åŒ–PyRosetta"""
        if self.rosetta_calc is None:
            self.rosetta_calc = PyRosettaCalculator(pdb_path)
        
    def load_custom_esm(self, protein_id):
        """åŠ è½½å•ä¸ªè›‹ç™½è´¨çš„å®Œæ•´ESMç‰¹å¾"""
        esm_path = os.path.join(self.config.custom_esm_dir, f"{protein_id}_full_esm.npz") 
        if os.path.exists(esm_path): 
            try:
                data = np.load(esm_path)
                print(f"æˆåŠŸåŠ è½½ESMç‰¹å¾æ–‡ä»¶: {esm_path}")
                return data['features']  # å½¢çŠ¶: [seq_len, esm_dim]
            except Exception as e:
                print(f"åŠ è½½ESMç‰¹å¾æ–‡ä»¶å¤±è´¥: {esm_path}, é”™è¯¯: {str(e)}")
                return None
        else:
            print(f"ESMç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {esm_path}")
            return None
    
    def prepare_protein_data(self, protein_id, protein_sequence, positions=None, pdb_path=None):
        """ä¼˜åŒ–åçš„æ•°æ®å‡†å¤‡æ–¹æ³•"""
        # ç¡®å®šé¢„æµ‹ä½ç‚¹
        if positions is None:
            positions = [i+1 for i, aa in enumerate(protein_sequence) 
                        if aa in self.config.target_aa] 
        
        # åˆå§‹åŒ– PyRosettaï¼ˆå»¶è¿Ÿï¼‰
        if pdb_path:
            self.init_pyrosetta(pdb_path)  # è¿™ä¼šåˆ›å»º self.rosetta_calc
        
        # åŠ è½½ESMç‰¹å¾
        esm_features = self._prepare_esm_features(protein_id, protein_sequence, positions)
        
        # ç”Ÿæˆç»“æ„ç‰¹å¾
        struct_features = self._generate_structural_features(positions)  # å†…éƒ¨ä½¿ç”¨ self.rosetta_calc
        
        # å‡†å¤‡åºåˆ—çª—å£
        X_seq = []
        for win_size in self.config.window_sizes: 
            seq_windows = self._get_sequence_windows(protein_sequence, positions, win_size)
            X_seq.append(self._encode_sequences(seq_windows)) 
        
        return X_seq, struct_features, esm_features, positions 
    
    def _prepare_esm_features(self, protein_id, protein_sequence, positions):
        """ESMç‰¹å¾å¤„ç†ä¼˜åŒ–"""
        custom_esm = self.load_custom_esm(protein_id) 
        esm_features = []
        
        for pos in positions:
            if custom_esm is not None and pos-1 < len(custom_esm):
                # æå–ç›®æ ‡ä½ç½®ESMç‰¹å¾å¹¶å¢å¼ºå…³é”®ä½ç‚¹ 
                feat = custom_esm[pos-1].copy()
               
                esm_features.append(feat) 
            else:
                # å›é€€åˆ°é›¶å¡«å…… 
                esm_features.append(np.zeros(self.config.esm_dim)) 
        return np.array(esm_features) 
    
    def _generate_structural_features(self, positions):
        """
        ç”Ÿæˆç»“æ„ç‰¹å¾ï¼ˆSASA, phi, psi, äºŒçº§ç»“æ„ï¼‰
        """
        features = np.zeros((len(positions), self.config.struct_feature_dim))
        
        if self.rosetta_calc is not None:
            for i, pos in enumerate(positions):
                try:
                    # è°ƒç”¨ PyRosetta è®¡ç®—å•ä¸ªæ®‹åŸºç‰¹å¾
                    feat = self.rosetta_calc.calculate_features(pos)
                    features[i] = feat
                except Exception as e:
                    print(f"è­¦å‘Šï¼šæ®‹åŸº {pos} ç»“æ„ç‰¹å¾è®¡ç®—å¤±è´¥: {str(e)}")
                    features[i] = self._get_default_features()
        else:
            # å¦‚æœæ²¡æœ‰ç»“æ„ï¼Œè¿”å›é»˜è®¤å€¼
            features = np.array([self._get_default_features() for _ in positions])
        
        return features  # â† æ›¿æ¢ä¸ºè¿™ä¸€è¡Œ
    
    def _get_default_features(self):
        """é»˜è®¤ç‰¹å¾å€¼ï¼ˆè®¡ç®—å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        return np.array([0.5, 0.0, 0.0, 0, 1, 0,85.0,85.0])  # [sasa, phi, psi, H, C, E]
    

    
    def _get_sequence_windows(self, sequence, positions, window_size):
        """è·å–åºåˆ—çª—å£"""
        half_len = (window_size - 1) // 2
        windows = []
        
        for pos in positions:
            center = sequence[pos-1]
            left = sequence[max(0, pos-1-half_len):pos-1]
            right = sequence[pos:min(len(sequence), pos+half_len)]
            
            left_pad = max(0, half_len - len(left))
            right_pad = max(0, half_len - len(right))
            
            window = '*' * left_pad + left + center + right + '*' * right_pad
            windows.append(window) 
        
        return windows
    
    def _encode_sequences(self, sequences):
        """åºåˆ—ç¼–ç """
        letter_dict = {
            "A":0, "C":1, "D":2, "E":3, "F":4, "G":5, "H":6, "I":7, "K":8, "L":9,
            "M":10, "N":11, "P":12, "Q":13, "R":14, "S":15, "T":16, "V":17, "W":18, "Y":19,
            "*":20 
        }
        
        encoded = np.zeros((len(sequences), len(sequences[0])), dtype=int)
        for i, seq in enumerate(sequences):
            for j, aa in enumerate(seq):
                encoded[i, j] = letter_dict.get(aa, 20)
        
        return encoded
 
# ==================== é¢„æµ‹å™¨ (ä¼˜åŒ–ç‰ˆ) ====================
class PTMPredictor:
    def __init__(self, config):
        self.config  = config 
        self.data_loader  = PTMPredictDataLoader(config)
        
        # åŠ è½½æ¨¡å‹ (åŒ…å«è‡ªå®šä¹‰å±‚)
        self.model  = load_model(
            config.model_path, 
            custom_objects={
                'PositionEmbedding': PositionEmbedding,
                'MultiHeadSelfAttention': MultiHeadSelfAttention,
                'TransformerBlock': TransformerBlock,
                'focal_loss': self.focal_loss 
            }
        )
    
    def focal_loss(self, y_true, y_pred):
        """ä¿æŒä¸è®­ç»ƒä¸€è‡´çš„æŸå¤±å‡½æ•°"""
        fl = tf.keras.losses.SigmoidFocalCrossEntropy(alpha=0.25,  gamma=2.0)
        return fl(y_true, y_pred)
    
    def predict_ptm_sites(self, protein_id, protein_sequence, positions=None, pdb_path=None):
        """
        é¢„æµ‹æ–¹æ³• - æ‰€æœ‰ä½ç‚¹ä¸€è‡´å¯¹å¾…
        """
        # åˆå§‹åŒ–PyRosettaï¼ˆå¦‚æœæœ‰PDBè·¯å¾„ï¼‰
        self.data_loader.init_pyrosetta(pdb_path)
        
        # å‡†å¤‡æ•°æ® 
        X_seq, struct_features, esm_features, positions = \
            self.data_loader.prepare_protein_data(protein_id, protein_sequence, positions, pdb_path)
        
        # é¢„æµ‹æ¦‚ç‡ 
        y_pred_proba = self.model.predict(X_seq + [struct_features, esm_features])[:, 1]
        
        # ç”Ÿæˆç»“æœDataFrame
        results = []
        for pos, proba in zip(positions, y_pred_proba):
            results.append({ 
                'protein_id': protein_id,
                'position': pos,
                'residue': protein_sequence[pos-1],
                'probability': proba,
                'prediction': 1 if proba >= 0.5 else 0
            })
        
        return pd.DataFrame(results)
 
# ==================== ä¸»ç¨‹åº ====================
if __name__ == "__main__":
    config = PredictConfig()
    predictor = PTMPredictor(config)
    
    pdb_path = "/root/autodl-tmp/DeepPTMPred/data/AF-P31749-F1-model_v4.pdb"
    protein_id = extract_protein_id_from_pdb_path(pdb_path)
    protein_sequence = extract_sequence_from_pdb(pdb_path, chain_id="A") #chain_id="A"å°±ä»£è¡¨Aé“¾
  
    all_st_positions = [i+1 for i, aa in enumerate(protein_sequence) if aa in ['S', 'T']]
    # è¿è¡Œé¢„æµ‹ 
    results_df = predictor.predict_ptm_sites(protein_id, protein_sequence, all_st_positions,pdb_path=pdb_path )
    
    # ä¿å­˜ç»“æœ 
    output_path = os.path.join(config.root_dir, f"{protein_id}_all_phospho_predictions34.csv") 
    results_df.to_csv(output_path, index=False)
    
    # æ‰“å°ç»“æœæ‘˜è¦
    print("=== ç£·é…¸åŒ–ä½ç‚¹é¢„æµ‹ç»“æœæ‘˜è¦ ===")
    print(f"æ€»S/Tä½ç‚¹æ•°: {len(results_df)}")
    print(f"\nå®Œæ•´ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    
    sites_of_interest = [202, 205, 231, 262, 356]  # å…³æ³¨çš„ä½ç‚¹é¢„æµ‹æ¦‚ç‡æ˜¾ç¤º
    print("\n=== å…³æ³¨çš„ä½ç‚¹é¢„æµ‹æ¦‚ç‡ ===")
    for pos in sites_of_interest:
        site_data = results_df[results_df['position'] == pos]
        if not site_data.empty:
            print(f"ä½ç½® {pos} ({protein_sequence[pos-1]}): é¢„æµ‹æ¦‚ç‡ = {site_data['probability'].values[0]:.3f}")
        else:
            print(f"ä½ç½® {pos}: è¯¥ä½ç½®ä¸æ˜¯S/Tæ®‹åŸºæˆ–ä¸åœ¨åºåˆ—ä¸­")
